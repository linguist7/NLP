{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"네이버 영화리뷰 분류.ipynb","provenance":[{"file_id":"1ehYQYbaWYk8l6AJANTT6q62MIiSB3gh0","timestamp":1660105578535},{"file_id":"13Xc-wTbvgieocM42Z6ANCiICkwqQIgDr","timestamp":1641055330254},{"file_id":"18L1b5G7ESFHSuPDipl5RsUdLifcsLbkX","timestamp":1636510120294}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"251310a8bd94491b91ca11e51cfd7c4d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_885aeb36cbff4ee3b116c41128756ef6","IPY_MODEL_0471f51220c44eb08259827ad67cb761","IPY_MODEL_56f08947cd994cb68d5b375a9c35a6f9"],"layout":"IPY_MODEL_f20755764b5642908fa89c8f9db0ff14"}},"885aeb36cbff4ee3b116c41128756ef6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c538ed9cd42c4a47a5f7784fe7b95fac","placeholder":"​","style":"IPY_MODEL_1224414791854178b925e5749c3f9d9b","value":"Downloading vocab.txt: 100%"}},"0471f51220c44eb08259827ad67cb761":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_86ed44eb556f453a9f397d68c5251d90","max":248477,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3e8f375453204e998a6e7d9cb60b8061","value":248477}},"56f08947cd994cb68d5b375a9c35a6f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffa12c3d794449a19d03b21429558bcf","placeholder":"​","style":"IPY_MODEL_ad9cc7c4324e4f5fb7d1afc26899c0af","value":" 243k/243k [00:00&lt;00:00, 1.67MB/s]"}},"f20755764b5642908fa89c8f9db0ff14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c538ed9cd42c4a47a5f7784fe7b95fac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1224414791854178b925e5749c3f9d9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86ed44eb556f453a9f397d68c5251d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e8f375453204e998a6e7d9cb60b8061":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ffa12c3d794449a19d03b21429558bcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad9cc7c4324e4f5fb7d1afc26899c0af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d05128e7b60f4c849ff514d2dff91a77":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35a58234c4f641c9bba20b79559c0ba8","IPY_MODEL_b86a1269b366459aa03ea955b53b8915","IPY_MODEL_4386dd3894fd479bab41c00c168eb0c5"],"layout":"IPY_MODEL_921c61f66fd040fc9a06fc3b7fc7faf6"}},"35a58234c4f641c9bba20b79559c0ba8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5238e74d41014954bcee5fb9d095e7a5","placeholder":"​","style":"IPY_MODEL_432eb973f4c94f7d90993693a777a0a9","value":"Downloading special_tokens_map.json: 100%"}},"b86a1269b366459aa03ea955b53b8915":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30c406e7584b415f9cd4e90f7424ccc9","max":125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ec4349693f04a26b7dca988b65cd78e","value":125}},"4386dd3894fd479bab41c00c168eb0c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2708ce1610a24383bd830d75e21694e3","placeholder":"​","style":"IPY_MODEL_b44405bcd5ec4c43926c472d71841eab","value":" 125/125 [00:00&lt;00:00, 4.65kB/s]"}},"921c61f66fd040fc9a06fc3b7fc7faf6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5238e74d41014954bcee5fb9d095e7a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"432eb973f4c94f7d90993693a777a0a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30c406e7584b415f9cd4e90f7424ccc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ec4349693f04a26b7dca988b65cd78e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2708ce1610a24383bd830d75e21694e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b44405bcd5ec4c43926c472d71841eab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1bbba3e470643c6a6ea3a39d26e829f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_581cd85251f94ba0a6281a8010c43689","IPY_MODEL_901e04d3cc26478392d7da590459ed26","IPY_MODEL_fcb4844339f1485c9b9e8f308672e18f"],"layout":"IPY_MODEL_97828759a7d44f6e8b9a3fa93208e167"}},"581cd85251f94ba0a6281a8010c43689":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fd1240b2f8b48018bdd2fb164cd43af","placeholder":"​","style":"IPY_MODEL_744d9109b8214218aa9d92c13df1e54b","value":"Downloading tokenizer_config.json: 100%"}},"901e04d3cc26478392d7da590459ed26":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f02cb639ed0949cba15aa57721b4aede","max":289,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf6cf40d4c404184a06e145da16e30e8","value":289}},"fcb4844339f1485c9b9e8f308672e18f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2462307fdac94fa7b748adc566916252","placeholder":"​","style":"IPY_MODEL_c44e100dea1d4fa39ed117dd32ea0ede","value":" 289/289 [00:00&lt;00:00, 11.4kB/s]"}},"97828759a7d44f6e8b9a3fa93208e167":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fd1240b2f8b48018bdd2fb164cd43af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"744d9109b8214218aa9d92c13df1e54b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f02cb639ed0949cba15aa57721b4aede":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf6cf40d4c404184a06e145da16e30e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2462307fdac94fa7b748adc566916252":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c44e100dea1d4fa39ed117dd32ea0ede":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a9bc10c44b3457ea5fdc2dbaf126a01":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_423a78e02304439daf7fee077cc500a1","IPY_MODEL_7008850f75a14f24b9a47d7eb8cab0c9","IPY_MODEL_3f69e8105e88462d90625f137a3a7a99"],"layout":"IPY_MODEL_0ce1b4f805fd4d16a02908c4f3d2cae6"}},"423a78e02304439daf7fee077cc500a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_044cbc44745348aa8d9f1bf718da7396","placeholder":"​","style":"IPY_MODEL_62af4c4c523b4a25926ad645120d7315","value":"Downloading config.json: 100%"}},"7008850f75a14f24b9a47d7eb8cab0c9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ec175ef74b742c49820b2d6b4394a1d","max":425,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4137a5010d294061bc5a618e7a28bf80","value":425}},"3f69e8105e88462d90625f137a3a7a99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7428b31e9254a4eb0dba2ccad68cc09","placeholder":"​","style":"IPY_MODEL_0b1eee47c5cc47bfb2d1bec22c4dee89","value":" 425/425 [00:00&lt;00:00, 15.2kB/s]"}},"0ce1b4f805fd4d16a02908c4f3d2cae6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"044cbc44745348aa8d9f1bf718da7396":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62af4c4c523b4a25926ad645120d7315":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ec175ef74b742c49820b2d6b4394a1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4137a5010d294061bc5a618e7a28bf80":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7428b31e9254a4eb0dba2ccad68cc09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b1eee47c5cc47bfb2d1bec22c4dee89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44b51a7eaed149ba828de23cab2c4962":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8464809965841069a5fd58a91c9244c","IPY_MODEL_35fcaeb66ef64b70a21c96b7159cfb8a","IPY_MODEL_96063d7156c5446fa70443b0ccd1d76a"],"layout":"IPY_MODEL_4102489b1e294cc8a2da2b036e7527d8"}},"f8464809965841069a5fd58a91c9244c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b93badced39b40f1a2c54d0444c97d55","placeholder":"​","style":"IPY_MODEL_dd9d84d2a7ae4baaa7c90fff07011fe1","value":"Downloading pytorch_model.bin: 100%"}},"35fcaeb66ef64b70a21c96b7159cfb8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4ade3c0ddee486f81d1d68b4f093b95","max":445025130,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d62878f76fb148a09c032780d76cf254","value":445025130}},"96063d7156c5446fa70443b0ccd1d76a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b3bc8c687ce4cad9fbd9d0ac1ba82ec","placeholder":"​","style":"IPY_MODEL_b243a10e65634d1799111a64da98e23e","value":" 424M/424M [00:07&lt;00:00, 63.1MB/s]"}},"4102489b1e294cc8a2da2b036e7527d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b93badced39b40f1a2c54d0444c97d55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd9d84d2a7ae4baaa7c90fff07011fe1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4ade3c0ddee486f81d1d68b4f093b95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d62878f76fb148a09c032780d76cf254":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4b3bc8c687ce4cad9fbd9d0ac1ba82ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b243a10e65634d1799111a64da98e23e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7TPztkdcdLO","executionInfo":{"status":"ok","timestamp":1660108804102,"user_tz":-540,"elapsed":10297,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"3d2bb0d1-3734-4ba5-cd14-24bd86e5e5e6"},"source":["pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 47.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 47.1 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 12.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"nY4HfcDXikCI","executionInfo":{"status":"ok","timestamp":1660108804103,"user_tz":-540,"elapsed":7,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"1470a3a2-1809-4225-dae7-fb9c77f068f2"},"source":["import transformers\n","transformers.__version__"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'4.21.1'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"HPC7cPCrnF0q","executionInfo":{"status":"ok","timestamp":1660108809666,"user_tz":-540,"elapsed":5568,"user":{"displayName":"안창덕","userId":"16004463410126697761"}}},"source":["import pandas as pd\n","import numpy as np\n","import urllib.request\n","import os\n","from tqdm import tqdm\n","import tensorflow as tf\n","from transformers import BertTokenizer, TFBertModel"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QYbuNR1tdJca","executionInfo":{"status":"ok","timestamp":1660108810403,"user_tz":-540,"elapsed":740,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"c687817e-6b7b-4452-f500-4cd2f1f979f9"},"source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('ratings_test.txt', <http.client.HTTPMessage at 0x7f0e28bd93d0>)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"opGrZfOseqRi","executionInfo":{"status":"ok","timestamp":1660108810817,"user_tz":-540,"elapsed":416,"user":{"displayName":"안창덕","userId":"16004463410126697761"}}},"source":["train_data = pd.read_table('ratings_train.txt')\n","test_data = pd.read_table('ratings_test.txt')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aiF5GOyxelOY","executionInfo":{"status":"ok","timestamp":1660108810817,"user_tz":-540,"elapsed":15,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"9096de3b-8a99-4e24-a37d-6cb1d6554101"},"source":["print('훈련용 리뷰 개수 :',len(train_data)) # 훈련용 리뷰 개수 출력"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련용 리뷰 개수 : 150000\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZfefWt-2eoDS","executionInfo":{"status":"ok","timestamp":1660108810818,"user_tz":-540,"elapsed":15,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"0e5d9f88-09e6-424c-e695-57897c0d7f83"},"source":["print('테스트용 리뷰 개수 :',len(test_data)) # 테스트용 리뷰 개수 출력"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["테스트용 리뷰 개수 : 50000\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"vvzQl1j7eqhS","executionInfo":{"status":"ok","timestamp":1660108810818,"user_tz":-540,"elapsed":13,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"8e136f17-5c14-4a3a-f954-909841845f19"},"source":["train_data[:5] # 상위 5개 출력"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         id                                           document  label\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"],"text/html":["\n","  <div id=\"df-c0e3266e-cacd-4f32-a96e-7a38501dc87f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0e3266e-cacd-4f32-a96e-7a38501dc87f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c0e3266e-cacd-4f32-a96e-7a38501dc87f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c0e3266e-cacd-4f32-a96e-7a38501dc87f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"W9ppfuX4erVK","executionInfo":{"status":"ok","timestamp":1660108810818,"user_tz":-540,"elapsed":12,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"f661ff8e-b047-41ce-a063-73ad5382916f"},"source":["test_data[:5] # 상위 5개 출력"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        id                                           document  label\n","0  6270596                                                굳 ㅋ      1\n","1  9274899                               GDNTOPCLASSINTHECLUB      0\n","2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n","3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n","4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"],"text/html":["\n","  <div id=\"df-294830d3-d73e-4fff-bc78-6e3a982377ec\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6270596</td>\n","      <td>굳 ㅋ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9274899</td>\n","      <td>GDNTOPCLASSINTHECLUB</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8544678</td>\n","      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6825595</td>\n","      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6723715</td>\n","      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-294830d3-d73e-4fff-bc78-6e3a982377ec')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-294830d3-d73e-4fff-bc78-6e3a982377ec button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-294830d3-d73e-4fff-bc78-6e3a982377ec');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vWSh9Lc-esFC","executionInfo":{"status":"ok","timestamp":1660108810818,"user_tz":-540,"elapsed":11,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"27c9a8ef-1eca-44eb-ff79-9a8fa763f68c"},"source":["train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n","train_data = train_data.reset_index(drop=True)\n","print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tAgd9TbRetIa","executionInfo":{"status":"ok","timestamp":1660108810819,"user_tz":-540,"elapsed":11,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"69339ab7-4d55-4bca-b448-42143b0b85bd"},"source":["test_data = test_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n","test_data = test_data.reset_index(drop=True)\n","print(test_data.isnull().values.any()) # Null 값이 존재하는지 확인"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q2qLL0Jpet8C","executionInfo":{"status":"ok","timestamp":1660108810819,"user_tz":-540,"elapsed":9,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"8ca43a76-8286-4346-e188-5959afca59e5"},"source":["print(len(train_data))"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["149995\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08SqlJG4euuq","executionInfo":{"status":"ok","timestamp":1660108810819,"user_tz":-540,"elapsed":8,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"fcf60a5a-917c-41aa-ed78-6f0a38e5dc92"},"source":["print(len(test_data))"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["49997\n"]}]},{"cell_type":"markdown","source":["1. 모델을 로드한다.  \n","2. 모델과 일치하는 토크나이저(문장을 정수 인코딩)를 로드한다.\n","\n"],"metadata":{"id":"6pixXpk7tNia"}},{"cell_type":"code","metadata":{"id":"Nx_D1rlXfcB6","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["251310a8bd94491b91ca11e51cfd7c4d","885aeb36cbff4ee3b116c41128756ef6","0471f51220c44eb08259827ad67cb761","56f08947cd994cb68d5b375a9c35a6f9","f20755764b5642908fa89c8f9db0ff14","c538ed9cd42c4a47a5f7784fe7b95fac","1224414791854178b925e5749c3f9d9b","86ed44eb556f453a9f397d68c5251d90","3e8f375453204e998a6e7d9cb60b8061","ffa12c3d794449a19d03b21429558bcf","ad9cc7c4324e4f5fb7d1afc26899c0af","d05128e7b60f4c849ff514d2dff91a77","35a58234c4f641c9bba20b79559c0ba8","b86a1269b366459aa03ea955b53b8915","4386dd3894fd479bab41c00c168eb0c5","921c61f66fd040fc9a06fc3b7fc7faf6","5238e74d41014954bcee5fb9d095e7a5","432eb973f4c94f7d90993693a777a0a9","30c406e7584b415f9cd4e90f7424ccc9","7ec4349693f04a26b7dca988b65cd78e","2708ce1610a24383bd830d75e21694e3","b44405bcd5ec4c43926c472d71841eab","c1bbba3e470643c6a6ea3a39d26e829f","581cd85251f94ba0a6281a8010c43689","901e04d3cc26478392d7da590459ed26","fcb4844339f1485c9b9e8f308672e18f","97828759a7d44f6e8b9a3fa93208e167","2fd1240b2f8b48018bdd2fb164cd43af","744d9109b8214218aa9d92c13df1e54b","f02cb639ed0949cba15aa57721b4aede","cf6cf40d4c404184a06e145da16e30e8","2462307fdac94fa7b748adc566916252","c44e100dea1d4fa39ed117dd32ea0ede","6a9bc10c44b3457ea5fdc2dbaf126a01","423a78e02304439daf7fee077cc500a1","7008850f75a14f24b9a47d7eb8cab0c9","3f69e8105e88462d90625f137a3a7a99","0ce1b4f805fd4d16a02908c4f3d2cae6","044cbc44745348aa8d9f1bf718da7396","62af4c4c523b4a25926ad645120d7315","2ec175ef74b742c49820b2d6b4394a1d","4137a5010d294061bc5a618e7a28bf80","b7428b31e9254a4eb0dba2ccad68cc09","0b1eee47c5cc47bfb2d1bec22c4dee89"]},"executionInfo":{"status":"ok","timestamp":1660108812455,"user_tz":-540,"elapsed":1643,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"cd6f45e0-1b1d-4132-8b4b-d0f3c4406d9c"},"source":["tokenizer = BertTokenizer.from_pretrained('klue/bert-base')"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading vocab.txt:   0%|          | 0.00/243k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"251310a8bd94491b91ca11e51cfd7c4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d05128e7b60f4c849ff514d2dff91a77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1bbba3e470643c6a6ea3a39d26e829f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a9bc10c44b3457ea5fdc2dbaf126a01"}},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gHigtMypgOKz","executionInfo":{"status":"ok","timestamp":1660108812455,"user_tz":-540,"elapsed":12,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"f9940f0a-f038-496c-a00d-3ae511223fd6"},"source":["print(tokenizer.encode(\"보는내내 그대로 들어맞는 예측 카리스마 없는 악역\"))"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[2, 1160, 2259, 2369, 2369, 4311, 20657, 2259, 5501, 13132, 1415, 2259, 23713, 3]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r47lhT54gmeD","executionInfo":{"status":"ok","timestamp":1660108812456,"user_tz":-540,"elapsed":12,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"9ddf6ea6-37bd-4529-d58c-f20e69924e83"},"source":["print(tokenizer.tokenize(\"보는내내 그대로 들어맞는 예측 카리스마 없는 악역\"))"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["['보', '##는', '##내', '##내', '그대로', '들어맞', '##는', '예측', '카리스마', '없', '##는', '악역']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"XIDFM-jEkKft","executionInfo":{"status":"ok","timestamp":1660108812456,"user_tz":-540,"elapsed":10,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"09c2ba09-fd15-41b2-d130-b243331d0de2"},"source":["tokenizer.decode(tokenizer.encode(\"보는내내 그대로 들어맞는 예측 카리스마 없는 악역\"))"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'[CLS] 보는내내 그대로 들어맞는 예측 카리스마 없는 악역 [SEP]'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"crCnp1NWkGQu","executionInfo":{"status":"ok","timestamp":1660108812456,"user_tz":-540,"elapsed":10,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"36a7a137-9682-4900-aee0-3ef3ab7f7fc4"},"source":["for elem in tokenizer.encode(\"보는내내 그대로 들어맞는 예측 카리스마 없는 악역\"):\n","  print(tokenizer.decode(elem))"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["[ C L S ]\n","보\n","# # 는\n","# # 내\n","# # 내\n","그 대 로\n","들 어 맞\n","# # 는\n","예 측\n","카 리 스 마\n","없\n","# # 는\n","악 역\n","[ S E P ]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kHO4iiqQhP6D","executionInfo":{"status":"ok","timestamp":1660108812457,"user_tz":-540,"elapsed":9,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"79b414cd-0337-4ec8-d338-ab29f4dc8fd6"},"source":["print(tokenizer.tokenize(\"전율을 일으키는 영화. 다시 보고싶은 영화\"))"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["['전', '##율', '##을', '일으키', '##는', '영화', '.', '다시', '보고', '##싶', '##은', '영화']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PTL9qUrvhRHz","executionInfo":{"status":"ok","timestamp":1660108812457,"user_tz":-540,"elapsed":8,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"e9489a41-b907-4c04-c42a-7ffdc393df57"},"source":["print(tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\"))"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["[2, 1537, 2534, 2069, 6572, 2259, 3771, 18, 3690, 4530, 2585, 2073, 3771, 3]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vaFHN_zahR4i","executionInfo":{"status":"ok","timestamp":1660108812871,"user_tz":-540,"elapsed":18,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"bd967cef-db49-4c5f-e332-d1e197b826a9"},"source":["for elem in tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\"):\n","  print(tokenizer.decode(elem))"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["[ C L S ]\n","전\n","# # 율\n","# # 을\n","일 으 키\n","# # 는\n","영 화\n",".\n","다 시\n","보 고\n","# # 싶\n","# # 은\n","영 화\n","[ S E P ]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aOmogNVXhS1S","executionInfo":{"status":"ok","timestamp":1660108812871,"user_tz":-540,"elapsed":15,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"207e12ea-9d82-4c31-ed2d-11a4b127acaa"},"source":["for elem in tokenizer.encode(\"happy birthday~!\"):\n","  print(tokenizer.decode(elem))"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["[ C L S ]\n","h a\n","# # p p\n","# # y\n","b\n","# # i r\n","# # t h\n","# # d a y\n","~\n","!\n","[ S E P ]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z3WINg5UhTzq","executionInfo":{"status":"ok","timestamp":1660108812871,"user_tz":-540,"elapsed":12,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"c3cf26c8-7dc2-421a-a303-3e2999ffa95b"},"source":["print(tokenizer.decode(2))"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["[ C L S ]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-EM6Nw-LhUqq","executionInfo":{"status":"ok","timestamp":1660108812872,"user_tz":-540,"elapsed":12,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"0859e2a8-7107-4402-c760-6f6fe09d60b7"},"source":["print(tokenizer.decode(3))"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["[ S E P ]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9fqNEYEgllB7","executionInfo":{"status":"ok","timestamp":1660108812872,"user_tz":-540,"elapsed":11,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"d14ad605-0f5f-46ee-a601-38f07e3c1184"},"source":["print(tokenizer.cls_token, ':', tokenizer.cls_token_id)\n","print(tokenizer.sep_token, ':' , tokenizer.sep_token_id)"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS] : 2\n","[SEP] : 3\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XFPXfrnomB_q","executionInfo":{"status":"ok","timestamp":1660108812872,"user_tz":-540,"elapsed":10,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"76f4f7ce-e604-44b4-fdf2-d80ca49d7ce0"},"source":["print(tokenizer.pad_token, ':', tokenizer.pad_token_id)"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["[PAD] : 0\n"]}]},{"cell_type":"code","metadata":{"id":"VhPmUfylhVRy","executionInfo":{"status":"ok","timestamp":1660108812872,"user_tz":-540,"elapsed":8,"user":{"displayName":"안창덕","userId":"16004463410126697761"}}},"source":["max_seq_len = 128"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GDnicNWphV-y","executionInfo":{"status":"ok","timestamp":1660108812873,"user_tz":-540,"elapsed":9,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"e239a366-877c-40c0-bdbc-274ba01fdf95"},"source":["encoded_result = tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\", max_length=max_seq_len, pad_to_max_length=True)\n","print(encoded_result)\n","print('길이 :', len(encoded_result))"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["[2, 1537, 2534, 2069, 6572, 2259, 3771, 18, 3690, 4530, 2585, 2073, 3771, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","길이 : 128\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qxyu7SXVhWzS","executionInfo":{"status":"ok","timestamp":1660108812873,"user_tz":-540,"elapsed":7,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"3e08d8f0-a785-4209-d5ca-e43284db72e9"},"source":["# 세그멘트 인풋\n","print([0]*max_seq_len)"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-z_odn7QhXzK","executionInfo":{"status":"ok","timestamp":1660108812873,"user_tz":-540,"elapsed":6,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"99c9da55-376d-489c-9ab4-8c1323a59b5b"},"source":["# 마스크 인풋\n","valid_num = len(tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\"))\n","print(valid_num * [1] + (max_seq_len - valid_num) * [0])"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}]},{"cell_type":"code","metadata":{"id":"qk8DJZ_khYgK","executionInfo":{"status":"ok","timestamp":1660108932055,"user_tz":-540,"elapsed":240,"user":{"displayName":"안창덕","userId":"16004463410126697761"}}},"source":["def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n","    \n","    input_ids, attention_masks, token_type_ids, data_labels = [], [], [], []\n","    \n","    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n","        input_id = tokenizer.encode(example, max_length=max_seq_len, pad_to_max_length=True) # 토크나이저 후 정수 인코딩\n","        padding_count = input_id.count(tokenizer.pad_token_id)   # 패딩된 0 이 몇개인지\n","        attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count              #-> 11111110000000\n","        token_type_id = [0] * max_seq_len # 00000000000000\n","\n","        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n","        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n","        assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n","\n","        input_ids.append(input_id)\n","        attention_masks.append(attention_mask)\n","        token_type_ids.append(token_type_id)\n","        data_labels.append(label)\n","\n","    input_ids = np.array(input_ids, dtype=int)\n","    attention_masks = np.array(attention_masks, dtype=int)\n","    token_type_ids = np.array(token_type_ids, dtype=int)\n","\n","    data_labels = np.asarray(data_labels, dtype=np.int32)\n","\n","    return (input_ids, attention_masks, token_type_ids), data_labels"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2q81CbrDhZYi","executionInfo":{"status":"ok","timestamp":1660108989905,"user_tz":-540,"elapsed":55551,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"7236f7d2-8f00-4cc3-cf50-c95603552312"},"source":["train_X, train_y = convert_examples_to_features(train_data['document'], train_data['label'], max_seq_len=max_seq_len, tokenizer=tokenizer)"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/149995 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","100%|██████████| 149995/149995 [00:51<00:00, 2901.79it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A0LLv-CchaTS","executionInfo":{"status":"ok","timestamp":1660109008706,"user_tz":-540,"elapsed":17917,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"1a7e9761-add2-40af-c83a-1e915f913269"},"source":["test_X, test_y = convert_examples_to_features(test_data['document'], test_data['label'], max_seq_len=max_seq_len, tokenizer=tokenizer)"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/49997 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","100%|██████████| 49997/49997 [00:16<00:00, 2947.05it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1NT5huFhbDy","executionInfo":{"status":"ok","timestamp":1637213605171,"user_tz":-540,"elapsed":27,"user":{"displayName":"WJ Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgY0G-Dffdgo6aV-ICicc4JvFsFzlLHjjE3EKA2Mg=s64","userId":"17609157229046208934"}},"outputId":"ee943384-75e9-487d-de1e-0d0bc82fd61d"},"source":["# 최대 길이: 128\n","input_id = train_X[0][0]\n","attention_mask = train_X[1][0]\n","token_type_id = train_X[2][0]\n","label = train_y[0]\n","\n","print('단어에 대한 정수 인코딩 :',input_id)\n","print('어텐션 마스크 :',attention_mask)\n","print('세그먼트 인코딩 :',token_type_id)\n","print('각 인코딩의 길이 :', len(input_id))\n","print('정수 인코딩 복원 :',tokenizer.decode(input_id))\n","print('레이블 :',label)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["단어에 대한 정수 인코딩 : [   2 1376  831 2604   18   18 4229 9801 2075 2203 2182 4243    3    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0]\n","어텐션 마스크 : [1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","세그먼트 인코딩 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","각 인코딩의 길이 : 128\n","정수 인코딩 복원 : [CLS] 아 더빙.. 진짜 짜증나네요 목소리 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","레이블 : 0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161,"referenced_widgets":["44b51a7eaed149ba828de23cab2c4962","f8464809965841069a5fd58a91c9244c","35fcaeb66ef64b70a21c96b7159cfb8a","96063d7156c5446fa70443b0ccd1d76a","4102489b1e294cc8a2da2b036e7527d8","b93badced39b40f1a2c54d0444c97d55","dd9d84d2a7ae4baaa7c90fff07011fe1","d4ade3c0ddee486f81d1d68b4f093b95","d62878f76fb148a09c032780d76cf254","4b3bc8c687ce4cad9fbd9d0ac1ba82ec","b243a10e65634d1799111a64da98e23e"]},"id":"dp6ZAIpYevaC","executionInfo":{"status":"ok","timestamp":1660109580862,"user_tz":-540,"elapsed":9325,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"8739ecc0-6674-4618-8aa7-ee7c96f91622"},"source":["model = TFBertModel.from_pretrained(\"klue/bert-base\", from_pt=True)"],"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/424M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44b51a7eaed149ba828de23cab2c4962"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'bert.embeddings.position_ids', 'cls.predictions.bias']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]}]},{"cell_type":"code","metadata":{"id":"K-_jc-ft8tUp"},"source":["max_seq_len = 128"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p_lt6RAclTjU","executionInfo":{"status":"ok","timestamp":1660109652968,"user_tz":-540,"elapsed":5294,"user":{"displayName":"안창덕","userId":"16004463410126697761"}}},"source":["input_ids_layer = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32)\n","attention_masks_layer = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32)\n","token_type_ids_layer = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32)\n","\n","outputs = model([input_ids_layer, attention_masks_layer, token_type_ids_layer])"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W68IEgzUlay_","executionInfo":{"status":"ok","timestamp":1637213621242,"user_tz":-540,"elapsed":33,"user":{"displayName":"WJ Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgY0G-Dffdgo6aV-ICicc4JvFsFzlLHjjE3EKA2Mg=s64","userId":"17609157229046208934"}},"outputId":"0d5a3a55-3830-4437-94c3-a2ab52de1616"},"source":["print(outputs)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'tf_bert_model')>, pooler_output=<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_bert_model')>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)\n"]}]},{"cell_type":"markdown","source":["(배치 크기, 문장 길이, BERT의 벡터 차원) ==> 입력된 문장의 모든 단어 위치에서의 맨 마지막 층의 벡터들."],"metadata":{"id":"miVioqpnwLy7"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FIZh3VRMlfE-","executionInfo":{"status":"ok","timestamp":1637213621243,"user_tz":-540,"elapsed":28,"user":{"displayName":"WJ Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgY0G-Dffdgo6aV-ICicc4JvFsFzlLHjjE3EKA2Mg=s64","userId":"17609157229046208934"}},"outputId":"1949fe55-cb10-4125-9448-0fed736dc78a"},"source":["print(outputs[0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["KerasTensor(type_spec=TensorSpec(shape=(None, 128, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model'\")\n"]}]},{"cell_type":"markdown","source":["(배치 크기, BERT의 벡터 차원) ===> 입력된 문장의 맨 앞 위치인 CLS 토큰 위치에서의 맨 마지막 층의 벡터."],"metadata":{"id":"5NapPwBLwRkC"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WJdoCSSylgc5","executionInfo":{"status":"ok","timestamp":1637213621243,"user_tz":-540,"elapsed":26,"user":{"displayName":"WJ Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgY0G-Dffdgo6aV-ICicc4JvFsFzlLHjjE3EKA2Mg=s64","userId":"17609157229046208934"}},"outputId":"94eddc9c-93c2-47b4-caca-68a62fe5ee68"},"source":["print(outputs[1])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["KerasTensor(type_spec=TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/pooler/dense/Tanh:0', description=\"created by layer 'tf_bert_model'\")\n"]}]},{"cell_type":"code","metadata":{"id":"21Xtk14tTECJ","executionInfo":{"status":"ok","timestamp":1660110042921,"user_tz":-540,"elapsed":246,"user":{"displayName":"안창덕","userId":"16004463410126697761"}}},"source":["class TFBertForSequenceClassification(tf.keras.Model):\n","    def __init__(self, model_name):\n","        super(TFBertForSequenceClassification, self).__init__()\n","        self.bert = TFBertModel.from_pretrained(model_name, from_pt=True)\n","        self.classifier = tf.keras.layers.Dense(1,\n","                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02),\n","                                                activation='sigmoid',\n","                                                name='classifier')\n","\n","    def call(self, inputs):\n","        input_ids, attention_mask, token_type_ids = inputs\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        cls_token = outputs[1]\n","        prediction = self.classifier(cls_token)\n","\n","        return prediction"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W0ZgufoPH5-b"},"source":["TPU 사용법 : https://wikidocs.net/119990"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_6nzezphcoy","executionInfo":{"status":"ok","timestamp":1660110122380,"user_tz":-540,"elapsed":8785,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"bc99ff5f-f5b3-4f0f-ecb4-0729829755d5"},"source":["# TPU 작동을 위한 코드\n","resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","tf.config.experimental_connect_to_cluster(resolver)\n","tf.tpu.experimental.initialize_tpu_system(resolver)"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.123.180.114:8470\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.123.180.114:8470\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.tpu.topology.Topology at 0x7f0e244f7b90>"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M-xMJuCjUxIn","executionInfo":{"status":"ok","timestamp":1660110122381,"user_tz":-540,"elapsed":14,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"cf547cbf-2fb4-4297-c836-9f29494e8a85"},"source":["strategy = tf.distribute.experimental.TPUStrategy(resolver)"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wz2VsrZnUeJf","executionInfo":{"status":"ok","timestamp":1660110217752,"user_tz":-540,"elapsed":35784,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"81380f64-d92e-4122-a75d-5f6c5b1ccffe"},"source":["with strategy.scope():\n","  model = TFBertForSequenceClassification(\"klue/bert-base\")\n","  optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n","  loss = tf.keras.losses.BinaryCrossentropy()\n","  model.compile(optimizer=optimizer, loss=loss, metrics = ['accuracy'])"],"execution_count":40,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'bert.embeddings.position_ids', 'cls.predictions.bias']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQEGFSnbU8U1","executionInfo":{"status":"ok","timestamp":1660110687090,"user_tz":-540,"elapsed":469045,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"fb732136-93f5-42dd-e027-14695b9de48b"},"source":["model.fit(train_X, train_y, epochs=2, batch_size=64, validation_split=0.2)"],"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","1875/1875 [==============================] - 279s 108ms/step - loss: 0.2812 - accuracy: 0.8810 - val_loss: 0.2415 - val_accuracy: 0.9037\n","Epoch 2/2\n","1875/1875 [==============================] - 186s 99ms/step - loss: 0.1884 - accuracy: 0.9253 - val_loss: 0.2545 - val_accuracy: 0.9038\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0e238bda50>"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zRMrp8dyVqQA","executionInfo":{"status":"ok","timestamp":1660110716968,"user_tz":-540,"elapsed":29888,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"1f619ec8-765f-4809-fd19-e800ce523134"},"source":["results = model.evaluate(test_X, test_y, batch_size=1024)\n","print(\"test loss, test acc: \", results)"],"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["49/49 [==============================] - 28s 396ms/step - loss: 0.2610 - accuracy: 0.8996\n","test loss, test acc:  [0.2609961926937103, 0.8995739817619324]\n"]}]},{"cell_type":"code","metadata":{"id":"S0smzz7Jh0Mw","executionInfo":{"status":"ok","timestamp":1660110716968,"user_tz":-540,"elapsed":4,"user":{"displayName":"안창덕","userId":"16004463410126697761"}}},"source":["def sentiment_predict(new_sentence):\n","  input_id = tokenizer.encode(new_sentence, max_length=max_seq_len, pad_to_max_length=True)\n","\n","  padding_count = input_id.count(tokenizer.pad_token_id)\n","  attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n","  token_type_id = [0] * max_seq_len\n","\n","  input_ids = np.array([input_id])\n","  attention_masks = np.array([attention_mask])\n","  token_type_ids = np.array([token_type_id])\n","\n","  encoded_input = [input_ids, attention_masks, token_type_ids]\n","  score = model.predict(encoded_input)[0][0]\n","\n","  if(score > 0.5):\n","    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n","  else:\n","    print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))"],"execution_count":43,"outputs":[]},{"cell_type":"code","source":["sentiment_predict('재밌기')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5fB0itUER-ll","executionInfo":{"status":"ok","timestamp":1660110761982,"user_tz":-540,"elapsed":748,"user":{"displayName":"안창덕","userId":"16004463410126697761"}},"outputId":"50eebec1-db9f-49de-94a1-2c8c50a217b1"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["89.61% 확률로 부정 리뷰입니다.\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CRA5_U3nkjKH","executionInfo":{"status":"ok","timestamp":1637214239383,"user_tz":-540,"elapsed":783,"user":{"displayName":"WJ Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgY0G-Dffdgo6aV-ICicc4JvFsFzlLHjjE3EKA2Mg=s64","userId":"17609157229046208934"}},"outputId":"0bf32e63-5cab-4c56-f199-67409875c626"},"source":["sentiment_predict('보던거라 계속보고있는데 전개도 느리고 주인공인 은희는 한두컷 나오면서 소극적인모습에 ')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["99.74% 확률로 부정 리뷰입니다.\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zqpAeDCGkkXj","executionInfo":{"status":"ok","timestamp":1637214269187,"user_tz":-540,"elapsed":804,"user":{"displayName":"WJ Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgY0G-Dffdgo6aV-ICicc4JvFsFzlLHjjE3EKA2Mg=s64","userId":"17609157229046208934"}},"outputId":"ae1fddae-416d-427f-a74c-4bc059696dec"},"source":["sentiment_predict(\"스토리는 확실히 실망이였지만 배우들 연기력이 대박이였다 특히 이제훈 연기 정말 ... 이 배우들로 이렇게밖에 만들지 못한 영화는 아쉽지만 배우들 연기력과 사운드는 정말 빛났던 영화. 기대하고 극장에서 보면 많이 실망했겠지만 평점보고 기대없이 집에서 편하게 보면 괜찮아요. 이제훈님 연기력은 최고인 것 같습니다\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["99.18% 확률로 긍정 리뷰입니다.\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OxifMVDekyov","executionInfo":{"status":"ok","timestamp":1637214284604,"user_tz":-540,"elapsed":786,"user":{"displayName":"WJ Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgY0G-Dffdgo6aV-ICicc4JvFsFzlLHjjE3EKA2Mg=s64","userId":"17609157229046208934"}},"outputId":"24de18b8-ff53-475e-9903-6a0a9ec8df1d"},"source":["sentiment_predict(\"남친이 이 영화를 보고 헤어지자고한 영화. 자유롭게 살고 싶다고 한다. 내가 무슨 나비를 잡은 덫마냥 나에겐 다시 보고싶지 않은 영화.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["96.73% 확률로 부정 리뷰입니다.\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4gSKfLXQk2Zv","executionInfo":{"status":"ok","timestamp":1637214312219,"user_tz":-540,"elapsed":760,"user":{"displayName":"WJ Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgY0G-Dffdgo6aV-ICicc4JvFsFzlLHjjE3EKA2Mg=s64","userId":"17609157229046208934"}},"outputId":"ebb4ec8d-7e8d-4a09-85cb-36a44fa6737d"},"source":["sentiment_predict(\"이 영화 존잼입니다 대박\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["98.12% 확률로 긍정 리뷰입니다.\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DIbeUn31lQ7P","executionInfo":{"status":"ok","timestamp":1637214393761,"user_tz":-540,"elapsed":739,"user":{"displayName":"WJ Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgY0G-Dffdgo6aV-ICicc4JvFsFzlLHjjE3EKA2Mg=s64","userId":"17609157229046208934"}},"outputId":"153f3621-1c1c-435b-a776-6cbfa723402a"},"source":["sentiment_predict('이 영화 개꿀잼 ㅋㅋㅋ')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["98.76% 확률로 긍정 리뷰입니다.\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v1RDXkDGlREX","executionInfo":{"status":"ok","timestamp":1637214403416,"user_tz":-540,"elapsed":757,"user":{"displayName":"WJ Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgY0G-Dffdgo6aV-ICicc4JvFsFzlLHjjE3EKA2Mg=s64","userId":"17609157229046208934"}},"outputId":"f91b7c7a-f985-48cc-bf22-110306248fad"},"source":["sentiment_predict('이 영화 핵노잼 ㅠㅠ')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["99.56% 확률로 부정 리뷰입니다.\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wGEMB2eUlR9n","executionInfo":{"status":"ok","timestamp":1637214406056,"user_tz":-540,"elapsed":1407,"user":{"displayName":"WJ Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgY0G-Dffdgo6aV-ICicc4JvFsFzlLHjjE3EKA2Mg=s64","userId":"17609157229046208934"}},"outputId":"2c2ca181-ed5f-4730-ae84-e14ced8b8a84"},"source":["sentiment_predict('이딴게 영화냐 ㅉㅉ')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["99.84% 확률로 부정 리뷰입니다.\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fm-oPBZllT2W","executionInfo":{"status":"ok","timestamp":1637214409516,"user_tz":-540,"elapsed":789,"user":{"displayName":"WJ Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgY0G-Dffdgo6aV-ICicc4JvFsFzlLHjjE3EKA2Mg=s64","userId":"17609157229046208934"}},"outputId":"34b3a337-48e1-4140-870f-907d8dfe56e2"},"source":["sentiment_predict('감독 뭐하는 놈이냐?')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["99.70% 확률로 부정 리뷰입니다.\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EyQ4oHewlU5-","executionInfo":{"status":"ok","timestamp":1637214413696,"user_tz":-540,"elapsed":727,"user":{"displayName":"WJ Y","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgY0G-Dffdgo6aV-ICicc4JvFsFzlLHjjE3EKA2Mg=s64","userId":"17609157229046208934"}},"outputId":"3f7cd1cc-d8c6-47a6-de62-4f230af6d90c"},"source":["sentiment_predict('와 개쩐다 정말 세계관 최강자들의 영화다')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["97.87% 확률로 긍정 리뷰입니다.\n","\n"]}]}]}